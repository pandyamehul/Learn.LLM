# Learn AI - LLM

- [Learn AI - LLM](#learn-ai---llm)
  - [Week 1](#week-1)
  - [Week 2](#week-2)
  - [Week 3](#week-3)
  - [Week 4](#week-4)
  - [Week 5](#week-5)

## Week 1

- Exercises and tasks related to LLMs, including API usage and model interactions.
- Includes notebooks for practical exercises and code snippets for working with LLMs.
- Environment setup for running LLMs locally or via APIs.
- Focus on understanding LLMs, their capabilities, and how to interact with them effectively.
- Includes examples of using OpenAI's API and Ollama for model interactions.
- Exercises include constructing API messages, handling responses, and streaming outputs from LLMs.

## Week 2

Day1:

- Exploration of Google Gemini, DeepSeek, and Anthropic's Claude models.
- Practical exercises using these models via their respective APIs.
- Includes examples of setting up system prompts, handling chat completions, and streaming responses.
- Example of conversation between different APIs, such as OpenAI and Google Gemini.

Day 2:

- Introduction to Gradio for building interactive UI applications with LLMs.
- Practical exercises on creating Gradio UI apps to interact with LLMs.

Day 3:

- Build chat bots using Gradio UI and OpenAI's API.
- Exercises on creating chat interfaces, handling user inputs, and displaying model responses.
- Implementation of context management for maintaining conversation history.

Day 4:

- Implemented AI Chatbot with integration of Ollama and OpenAI models.
- Intorcution and usage of tools in chatbot

Day 5:

- Multi-modal AI chatbots using OpenAI's DALL-E for image generation and speech models.
- Integrated audio generation using OpenAI's speech model.
- Exploration of agentic AI concepts, including breaking down complex tasks and using multiple LLMs for specialized tasks.
- Introduction to building multi-modal chatbots that can handle both voice and image inputs.
- Practical exercises on creating a multi-modal AI assistant for airline travel, integrating voice and image capabilities.
- Includes examples of using OpenAI's API for image generation and audio synthesis.

Additional End of week Exercise - week 2

- Now use everything you've learned from Week 2 to build a full prototype for the technical question/answerer you built in Week 1 Exercise.
- This should include a Gradio UI, streaming, use of the system prompt to add expertise, and the ability to switch between models. Bonus points if you can demonstrate use of a tool!
- If you feel bold, see if you can add audio input so you can talk to it, and have it respond with audio. ChatGPT or Claude can help you, or email me if you have questions.
- There are so many commercial applications for this, from a language tutor, to a company onboarding solution, to a companion AI to a course (like this one!).

Challange to Explore:

- Add more Tools / Agents to enhance capabilities: Add another Tool to make a booking
- Add an Agent that translates all responses to a different language and shows on the right hand side, using a different Frontier model
- Add an Agent that can listen for Audio and convert it to Text

What you can now do

- Describe transformers and explain key terminology
- Confidently code with the APIs for GPT, Claude and Gemini
- Build a multi-modal AI Assistant with UI, Tools, Agents

## Week 3

Challange to Explore:

Generating Synthetic Data

- Write models that can generate datasets
- Use a variety of models and prompts for diverse outputs
- Create a Gradio UI for your product

What you can now do

- Confidently code with Frontier Models
- Build a multi-modal AI Assistant with Tools
- Build an LLM solution combining frontier and open-source models

## Week 4

Day 1, 2:

- Hugging Face Open LLM Leaderboard for comparing open source language models.
- Understand top 6 leader boards categories and their evaluation metrics viz. HuggingFace Open LLM, HuggingFace BigCode, HuggingFace LLM Perf, HuggingFace Others, Vellum, SEAL.
- Vellum.ai to compare open and close source models and performance.
- seal.com/leaderboard - another website to compare model performance.
- lmarena.ai/leaderboard - leaderboard to compare llm chatboats and their performance. ref. chatboat arena leaderboard.
- Harvy.ai
- Nebula.io - for resume and help manager to short list resume
- Bloop - legacy code conversion
- Saleforce.com
- Khanmigo.ai
- lmarena.ai
- scale.com/leaderboard/coding

Day 3:

- Created a C++ code generator using OpenAI's API.
- Integrated the code generator into a Gradio UI for interactive code generation.
- Added functionality to compile and run the generated C++ code within the Gradio interface.
- lmarena.ai/leaderboard - leaderboard to compare llm chatboats and their performance.

Day 4:

- Understanding of how open source models can be used and implemented to code generation task using HuggingFace inference endpoints.
- Deploy model on AWS or Azure or GCP for production use. Here, open source models will be installed on selected cloud compute, it provides end point to interact with deployed open source model.

Day 5:

- To be updated

Challange to Explore:

For this high performance coding solution

- Try adding Gemini to the Closed Source mix
- Try more open-source models such as CodeLlama and StarCoder, and see if you can get CodeGemma to work

3 new, exciting code generation ideas:

- A code tool that automatically adds docstring / comments
- A code gen tool that writes unit test cases
- A code generator that writes trading code to buy and sell equities in a simulated environment, based on a given API.

What you can now do

- Code with Frontier Models including AI Assistants with Tools, and with open-source models with HuggingFace transformers
- Confidently choose the right LLM for your project, backed by metrics
- Build solutions to generate code with Frontier and open-source LLMs

## Week 5

Day 1:

- Implemented simple, brute-force RAG (Retrieval-Augmented Generation) pipeline using OpenAI's API.
- Integrated the RAG pipeline into a Gradio UI for interactive document retrieval and question answering.
- Added functionality to handle user messages and maintain chat history.
- Implemented a context-aware chat feature to improve response relevance.
- Added a function to enrich user messages with relevant context before sending them to the model.

Day 2:

- 